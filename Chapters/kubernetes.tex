%************************************************
\chapter{Kubernetes}\label{ch:kubernetes}
%************************************************
Topic 3: Write a brief introduction to the Kubernetes container cluster manager. 
Design, develop, test, and document a functional proof-of-concept prototype using the Kubernetes container cluster manager. 

This topic builds on top of the previous two topics 1 and 2 and should be able to:\\
- deploy all containerized services in Kubernetes on the Raspberry Pi cluster \\
- scale pods in Kubernetes \\
- update pods with rolling-update \\

\textbf{What is Kubernetes?}\\
Kubernetes is a cluster management tool made by google to manage containerized applications. Kubernetes takes a bunch of nodes and make them appear as a one big computer and deploy container applications to the public or private cloud based on preference. Kubernetes abstracts away the discrete nodes and optimizes compute resources.  

Moreover, Kubernetes make use of a declarative approach to get the desired state for the application mentioned by the user. 

Whenever an application is deployed onto the cluster, the Kubernetes' master node have to decide and deploy the application to the correct host. Kubernetes does all the heavy lifting by using its scheduler. 

Furthermore, Kubernetes is used for automating management of containers such as scaling, loadbalancing and scheduling containers between nodes in a cluster. Kubernetes makes the cluster environment much more robust for container deployment.

Containers in Kubernetes are run inside pods. A pod is can contain a single or a group of containers which are scheduled onto the same host. They are used to gather containers that are tightly coupled to each other under the same host such that communication between containers becomes easier. Every pod has it's own ip address. Kubernetes schedules, deploy and scale pods such they among other ensure that the load is balanced in the cluster. 

The containers or the pods in the nodes can be replicated, so if one node fails Kubernetes will create a new pod on another node and run the container within this newly created pod. The Kubernetes keeps track of all the living pods using its built-in registry service.  
If there suddenly comes a lot of load on a specific node it will make extra \emph{replicaset} of the pods so that the load is distributed between these pods and thereby the load is more balanced but only if the Kubernetes is set to autoscale. 

\section{PoC of Kubernetes}
Before running the containerized services within Kubernetes the verifying process was to run them on the local machine. As the services was behaving as intended on the local machine, it was verified that they were ready for beeing deployed as Docker containers inside Kubernetes on the cluster. 

For running these services as Docker containers on the cluster it is necessary to put the service inside a Docker container from the cluster instead of locally.

To deploy the service to Kubernetes its essential to build jar file within the cluster to have the rightful configuration setup.

In the following step the Dockerfile is run on the cluster which puts the service inside a Docker container. When the service is packed within Docker container the service is then pushed to Docker hub.   

To run the containerized service inside of Kubernetes on the Raspberry Pi cluster the following command is used:

\begin{lstlisting}
COMMAND 
\end{lstlisting}

This command deploys the Docker container on Kubernetes. 

Within Kubernetes the Yaml file is used to describe the available resources and the number of replicas. It can be seen below:

\begin{lstlisting}
Yaml
\end{lstlisting}


%results image
Secondly we scale number pods:
%results image

Lastly we update the pods, using rolling-update:
%results image



%profiles - development port and default port
%jar file
%docker hub repository


%\begin{figure}[bth]
%	\includegraphics[width=1\linewidth]{gfx/pastry-routing}
%	\caption[routingtable]{Routing table for Pastry} \label{fig:pastryrouting}
%\end{figure}